{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.8 Homework :  Deployment (Answers)\n",
    "Panayotis Papoutsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)\n",
    "\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 2\n",
    "df = read_data(f'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_{year:04d}-{month:02d}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean predicted for the February 2021 FVH dataset is 16.19 minutes.\n"
     ]
    }
   ],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "pred_mean = np.round(np.mean(y_pred),2)\n",
    "print(f'The mean predicted for the February 2021 FVH dataset is {pred_mean} minutes.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Preparing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-8.0.0-cp39-cp39-macosx_11_0_arm64.whl (16.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages (from pyarrow) (1.22.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-8.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ride_id'] = df['ride_id']\n",
    "df_result['predicted_duration'] = y_pred\n",
    "\n",
    "output_file = f'data/predictions_fhv_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19M\tdata/predictions_fhv_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/*.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Creating the scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command to transform a jupyter notebook into a script is : jupyter nbconvert --to script homework-answer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script starter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipenv\n",
      "  Using cached pipenv-2022.6.7-py2.py3-none-any.whl (3.9 MB)\n",
      "Requirement already satisfied: pip>=22.0.4 in /opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages (from pipenv) (22.1.2)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages (from pipenv) (2022.5.18.1)\n",
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.15.0-py2.py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=36.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages (from pipenv) (62.3.2)\n",
      "Collecting virtualenv-clone>=0.2.5\n",
      "  Using cached virtualenv_clone-0.5.7-py3-none-any.whl (6.6 kB)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Using cached distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "Collecting platformdirs<3,>=2\n",
      "  Using cached platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/exp-tracking-env/lib/python3.9/site-packages (from virtualenv->pipenv) (1.16.0)\n",
      "Collecting filelock<4,>=3.2\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: distlib, virtualenv-clone, platformdirs, filelock, virtualenv, pipenv\n",
      "Successfully installed distlib-0.3.4 filelock-3.7.1 pipenv-2022.6.7 platformdirs-2.5.2 virtualenv-20.15.0 virtualenv-clone-0.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mscikit-learn==1.0.2\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mscikit-learn\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mpyarrow\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mpyarrow\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mpandas\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mpandas\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mnumpy\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mnumpy\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mmlflow\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mmlflow\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mprefect==2.0b6\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mprefect\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
      "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (b41608)...\u001b[39m\u001b[22m\n",
      "  🐍   \u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m 2/2 — \u001b[30m\u001b[22m00:00:00\u001b[39m\u001b[22m:00:00\u001b[39m\u001b[22m:00:00\u001b[39m\u001b[22m\n",
      "To activate this project's virtualenv, run \u001b[33m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv install scikit-learn==1.0.2 pyarrow pandas numpy mlflow prefect==2.0b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            \"version\": \"==0.6.0\"\n",
      "        },\n",
      "        \"scikit-learn\": {\n",
      "            \"hashes\": [\n",
      "                \"sha256:08ef968f6b72033c16c479c966bf37ccd49b06ea91b765e1cc27afefe723920b\",\n"
     ]
    }
   ],
   "source": [
    "!cat Pipfile.lock | grep -2 scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Parametrize the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.3\n"
     ]
    }
   ],
   "source": [
    "!python starter.py 2021 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from flask import Flask, request, jsonify\n",
      "import numpy as np\n",
      "import pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "\n",
      "def load_dic(file):\n",
      "    with open(file, 'rb') as f_in:\n",
      "        dv, lr = pickle.load(f_in)\n",
      "    return dv,lr\n",
      "    \n",
      "def read_data(filename):\n",
      "    df = pd.read_parquet(filename)\n",
      "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
      "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
      "\n",
      "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
      "    return df\n",
      "\n",
      "def data_processing(year,month):\n",
      "\n",
      "    df = read_data(f'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_{year:04d}-{month:02d}.parquet')\n",
      "    categorical = ['PUlocationID', 'DOlocationID']\n",
      "    dv, lr = load_dic('model.bin')\n",
      "    dicts = df[categorical].to_dict(orient='records')\n",
      "\n",
      "    X_val = dv.transform(dicts)\n",
      "    return lr,X_val\n",
      "\n",
      "def predict(lr,X_val):\n",
      "    y_pred = lr.predict(X_val)\n",
      "    #pred_mean = np.round(np.mean(y_pred),2)\n",
      "    return y_pred\n",
      "\n",
      "\n",
      "app = Flask('homework-week4')    \n",
      "\n",
      "@app.route('/predict', methods=['POST'])\n",
      "def end_point():\n",
      "\n",
      "    date = request.get_json()\n",
      "\n",
      "    year, month = date['year'], date['month']\n",
      "\n",
      "    lr, X_val = data_processing(year, month)\n",
      "    pred = predict(lr,X_val)\n",
      "\n",
      "    result = {\n",
      "        'mean prediction': np.round(np.mean(pred),2)\n",
      "    }\n",
      "    return jsonify(result)\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True, host='0.0.0.0', port=9696)"
     ]
    }
   ],
   "source": [
    "!cat docker_starter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import requests\n",
      "\n",
      "date = {\"year\" : 2021,\n",
      "        \"month\": 4}\n",
      "\n",
      "url = 'http://localhost:9696/predict'\n",
      "rep = requests.post(url,json = date)\n",
      "\n",
      "print(rep.json())"
     ]
    }
   ],
   "source": [
    "!cat test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flask application is tested with test.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean prediction': 21.58}\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the image with this command : `docker build -t mean-duration-service:v1 .`. Next, we launch the docker image with `docker run -it --rm -p 9696:9696 mean-duration-service:v1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean prediction': 21.58}\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest answer is `25.96`, not `16.55` as in my answer in the google form. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bonus: upload the result to the cloud (Not graded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By replacing the line `output_file =  f'predictions_fhv_tripdata_{year:04d}-{month:02d}.parquet'` with `output_file = f's3://mlflow-artifacts-remote-store/homework-week4/predictions_fhv_tripdata_{year:04d}-{month:02d}.parquet'`in the docker_starter.py . The prerequisite is to run the script from the EC2 instance that is associated with the S3 bucket `mlflow-artifacts-remote-store`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('exp-tracking-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b175eb01e3a7d9a948fd024fda99c4e5ce3a209ce6ee7834e2c666f3cb350ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
